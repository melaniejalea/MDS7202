{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Aut贸nomos </center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci贸n Cient铆fica para Ciencia de Datos</strong></center>"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol谩s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no ser谩n revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb",
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr",
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci贸n del laboratorio](#Descripci贸n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementaci贸n de modelos de LLM y Reinforcement Learning.\n",
        "- Utilizaci贸n e implementaci贸n de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 d铆as desde la publicaci贸n, 3 d铆as de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia ser谩 debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est茅n en u-cursos no ser谩n revisados. Recuerden que el repositorio tambi茅n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser谩n respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deber谩 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m谩ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m谩s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ],
      "metadata": {
        "id": "Is4P4NDMurx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "tJ3yV96HwN75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joaqu铆n no es un aficionado del cine, pero a principios de a帽o, se propuso ver m谩s peliculas para poder tener m谩s temas de conversaci贸n con sus amigos y familia. Sin embargo, ya es junio y Joaqu铆n no ha visto ninguna pelicula nueva o relevante de las que ten铆a en su lista y su reuni贸n familiar bi-anual se acerca y necesita la mayor informaci贸n que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compa帽erx, tendr谩 que crear una aplicaci贸n utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kB8z1qrGww4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalaci贸n de librer铆as**\n",
        "\n",
        "Para la creaci贸n de la aplicaci贸n, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizar谩 la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ah铆, ir a la pesta帽a superior y seleccione la opci贸n que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el bot贸n que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podr谩 consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor informaci贸n sobre **LangChain**, pueden revisar la documentaci贸n en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ],
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS_6MjRoWYMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDjqTKKF_DLXSEe49aXwcjnAHWNiYtZ8tU\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ],
      "metadata": {
        "id": "kUgbzVtWUYq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para iniciar su titanica tarea de ense帽arle a Joaqu铆n sobre las mejores peliculas del 煤ltimo tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patr贸n y obtener solamente el gui贸n de las pel铆culas. Para ello se recomienda utilizar m茅todos de b煤squeda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patr贸n se repite y es generalizable.\n"
      ],
      "metadata": {
        "id": "6I10Li9a7nez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ],
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def load_website_data(url):\n",
        "  '''\n",
        "  Escriba su c贸digo ac谩\n",
        "  '''\n",
        "  return website_data\n",
        "\n",
        "def remove_text_before_marker(text):\n",
        "    '''\n",
        "    Escriba su c贸digo ac谩\n",
        "    '''\n",
        "    return text_out"
      ],
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Aplicaci贸n (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaic贸n deseada con el LLM. Esta aplicaci贸n tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la pel铆cula.\n",
        "\n",
        "2. Genere un resumen en espa帽ol de la pel铆cula y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 p谩rrafos. Adem谩s, obtener una evaluaci贸n de la pel铆cula con una calificaci贸n del 1 al 10, utilizando una LLM y el contexto entregado"
      ],
      "metadata": {
        "id": "7Btad-nZ9EyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 T铆tulo de la pel铆cula (0.5 puntos)**\n",
        "\n",
        "Para obtener el t铆tulo, utilic茅 la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QcS80oN2-Gq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  '''\n",
        "  Escriba su c贸digo ac谩\n",
        "  '''\n",
        "  return result.content.strip()"
      ],
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vi贸 en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tama帽o del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ],
      "metadata": {
        "id": "muDXLfr0CabX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No cambiar funci贸n\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un m谩ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  # resultado\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ],
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "answer_summary = \"\"\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir resumenes de pel铆culas."
      ],
      "metadata": {
        "id": "ijib42GaIFSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, Joaqu铆n sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustar铆a tener mayor informaci贸n al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gr谩fico que muestre los personajes de la pel铆cula con m谩s apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que m谩s aparecen, indicando el nombre del actor y su edad actual m谩s uno (ojo edad + 1).\n",
        "5. Cree una funci贸n que responda preguntas sobre la pel铆cula bas谩ndose en la informaci贸n del texto entregado (OJO: las preguntas y salidas deben ser en espa帽ol). Luego, responda las siguientes preguntas:\n",
        "* 驴Qu茅 y qui茅n es Lisan al-Gaib?\n",
        "* 驴Qu茅 personaje no cree en la profec铆a pero es parte de ella?\n",
        "* 驴Cu谩l es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que m谩s aparecen en la pel铆cula, genere con el modelo LLM y utilizando el contexto del guion, las 6 estad铆sticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ],
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente secci贸n, tiene que entregar un template de personajes y redicci贸n"
      ],
      "metadata": {
        "id": "e_vdMMceJZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    website_data_1,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ],
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = # ...\n",
        "  characters = #...\n",
        "\n",
        "  # distil the characters output\n",
        "  \"\"\"\n",
        "  Recomendaci贸n, utilizar un diccionario para ordenar los personajes\n",
        "  \"\"\"\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  # Graficar datos\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return\n"
      ],
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja informaci贸n de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar b煤squedas que nos ayuden a completar la informaci贸n consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ],
      "metadata": {
        "id": "2G2dx0XoLis4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ],
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ],
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = # ...\n",
        "  agent = # ...\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la b煤squeda.\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicar metodolog铆a utilizada**"
      ],
      "metadata": {
        "id": "Kpf9H61qMxal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estad铆sticas basandonos en una b煤squeda por map/reduce.\n",
        "\n",
        "Tras la b煤squeda, la idea es tener una funci贸n de Python que nos permita generar el gr谩fico deseado y tener el resumen de los personajes.\n"
      ],
      "metadata": {
        "id": "MtQqA40sM09E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducci贸n.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un m谩ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ],
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ],
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_profile)"
      ],
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci贸n para gr谩ficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ],
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodolog铆a y secuencia l贸gica de cada una de las respuestas. Adem谩s responda:\n",
        "\n",
        "* 驴Qu茅 otras tareas se podr铆a realizar? De dos ejemplos con la metodolog铆a asociada.\n",
        "\n",
        "* 驴Cual es la importancia de los prompt y como estos afectan al desempe帽o de los LLM?\n",
        "\n",
        "* 驴Alguna de sus respuestas fue una 'alucinaci贸n'? 驴Por qu茅 sucede esto?"
      ],
      "metadata": {
        "id": "_APhHBPXQXTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci贸n van a usar m茅todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "8445bc8e-2de6-4342-f789-1c3ce6d18cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaqu铆n es fan谩tico del Blackjack, por lo que en esta subsecci贸n implementar谩n m茅todos de RL y as铆 generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c贸digo transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Descripci贸n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci贸n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci贸n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Escriba su respuesta ac谩`"
      ],
      "metadata": {
        "id": "G5i1Wt1p770x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulaci贸n 5000 veces y reporte el promedio y desviaci贸n de las recompensas.\n",
        "* 驴C贸mo calificar铆a el performance de esta pol铆tica?\n",
        "* 驴C贸mo podr铆a interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "RHCfKN7NGi1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "T0sp8XWsGg4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 Evaluaci贸n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* 驴C贸mo es el performance de su agente?\n",
        "* 驴Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "S7jdmnTwGePD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una funci贸n que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta funci贸n para entregar la acci贸n escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* 驴Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: 驴A que clase de python pertenecen los estados? Pruebe a usar el m茅todo `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "Lssdp7AvGaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci贸n 2.1, en esta secci贸n usted se encargar谩 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Descripci贸n de MDP (0.2 puntos)**\n"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comencemos preparando el ambiente:"
      ],
      "metadata": {
        "id": "XvAVq1wQIjLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par谩metro continuous = True"
      ],
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Entregue una breve descripci贸n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci贸n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* 驴Como se distinguen las acciones de este ambiente en comparaci贸n a `Blackjack`?\n",
        "* En la preparaci贸n del ambiente se especifica el par谩metro `continuous = True`. 驴Que implicancias tiene esto sobre el ambiente?"
      ],
      "metadata": {
        "id": "LNERH-m8JYQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Escriba su respuesta ac谩`"
      ],
      "metadata": {
        "id": "DbpGahPcHAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci贸n 10 veces y reporte el promedio y desviaci贸n de las recompensas.\n",
        "* 驴C贸mo calificar铆a el performance de esta pol铆tica?"
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "pNMT_GORIreW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "Mg0epSnLKfy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 Evaluaci贸n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* 驴C贸mo es el performance de su agente? 驴Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "CWVY1a39KeRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.5 Optimizaci贸n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par谩metros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la funci贸n `export_gif` entregada para estudiar el comportamiento de su agente en la resoluci贸n del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, adem谩s, adjuntan el gif en el markdown tendr谩n un bonus de 0.1."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci贸n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta ac谩"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}