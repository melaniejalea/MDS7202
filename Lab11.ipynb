{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Autónomos 🤖</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicolás Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no serán revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb",
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr",
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementación de modelos de LLM y Reinforcement Learning.\n",
        "- Utilización e implementación de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 días desde la publicación, 3 días de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ],
      "metadata": {
        "id": "Is4P4NDMurx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "tJ3yV96HwN75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joaquín no es un aficionado del cine, pero a principios de año, se propuso ver más peliculas para poder tener más temas de conversación con sus amigos y familia. Sin embargo, ya es junio y Joaquín no ha visto ninguna pelicula nueva o relevante de las que tenía en su lista y su reunión familiar bi-anual se acerca y necesita la mayor información que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compañerx, tendrá que crear una aplicación utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kB8z1qrGww4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalación de librerías**\n",
        "\n",
        "Para la creación de la aplicación, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizará la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ahí, ir a la pestaña superior y seleccione la opción que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el botón que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podrá consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor información sobre **LangChain**, pueden revisar la documentación en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ],
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS_6MjRoWYMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDjqTKKF_DLXSEe49aXwcjnAHWNiYtZ8tU\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ],
      "metadata": {
        "id": "kUgbzVtWUYq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para iniciar su titanica tarea de enseñarle a Joaquín sobre las mejores peliculas del último tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patrón y obtener solamente el guión de las películas. Para ello se recomienda utilizar métodos de búsqueda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patrón se repite y es generalizable.\n"
      ],
      "metadata": {
        "id": "6I10Li9a7nez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ],
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def load_website_data(url):\n",
        "  '''\n",
        "  Escriba su código acá\n",
        "  '''\n",
        "  return website_data\n",
        "\n",
        "def remove_text_before_marker(text):\n",
        "    '''\n",
        "    Escriba su código acá\n",
        "    '''\n",
        "    return text_out"
      ],
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Aplicación (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaicón deseada con el LLM. Esta aplicación tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la película.\n",
        "\n",
        "2. Genere un resumen en español de la película y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 párrafos. Además, obtener una evaluación de la película con una calificación del 1 al 10, utilizando una LLM y el contexto entregado"
      ],
      "metadata": {
        "id": "7Btad-nZ9EyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 Título de la película (0.5 puntos)**\n",
        "\n",
        "Para obtener el título, utilicé la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QcS80oN2-Gq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  '''\n",
        "  Escriba su código acá\n",
        "  '''\n",
        "  return result.content.strip()"
      ],
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vió en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tamaño del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ],
      "metadata": {
        "id": "muDXLfr0CabX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No cambiar función\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  # resultado\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ],
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "answer_summary = \"\"\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir resumenes de películas."
      ],
      "metadata": {
        "id": "ijib42GaIFSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, Joaquín sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustaría tener mayor información al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gráfico que muestre los personajes de la película con más apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que más aparecen, indicando el nombre del actor y su edad actual más uno (ojo edad + 1).\n",
        "5. Cree una función que responda preguntas sobre la película basándose en la información del texto entregado (OJO: las preguntas y salidas deben ser en español). Luego, responda las siguientes preguntas:\n",
        "* ¿Qué y quién es Lisan al-Gaib?\n",
        "* ¿Qué personaje no cree en la profecía pero es parte de ella?\n",
        "* ¿Cuál es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que más aparecen en la película, genere con el modelo LLM y utilizando el contexto del guion, las 6 estadísticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ],
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente sección, tiene que entregar un template de personajes y redicción"
      ],
      "metadata": {
        "id": "e_vdMMceJZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    website_data_1,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ],
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = # ...\n",
        "  characters = #...\n",
        "\n",
        "  # distil the characters output\n",
        "  \"\"\"\n",
        "  Recomendación, utilizar un diccionario para ordenar los personajes\n",
        "  \"\"\"\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  # Graficar datos\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return\n"
      ],
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja información de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar búsquedas que nos ayuden a completar la información consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ],
      "metadata": {
        "id": "2G2dx0XoLis4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ],
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ],
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = # ...\n",
        "  agent = # ...\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la búsqueda.\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicar metodología utilizada**"
      ],
      "metadata": {
        "id": "Kpf9H61qMxal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estadísticas basandonos en una búsqueda por map/reduce.\n",
        "\n",
        "Tras la búsqueda, la idea es tener una función de Python que nos permita generar el gráfico deseado y tener el resumen de los personajes.\n"
      ],
      "metadata": {
        "id": "MtQqA40sM09E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducción.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ],
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escriba su respuesta acá"
      ],
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ],
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_profile)"
      ],
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para gráficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ],
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodología y secuencia lógica de cada una de las respuestas. Además responda:\n",
        "\n",
        "* ¿Qué otras tareas se podría realizar? De dos ejemplos con la metodología asociada.\n",
        "\n",
        "* ¿Cual es la importancia de los prompt y como estos afectan al desempeño de los LLM?\n",
        "\n",
        "* ¿Alguna de sus respuestas fue una 'alucinación'? ¿Por qué sucede esto?"
      ],
      "metadata": {
        "id": "_APhHBPXQXTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "8445bc8e-2de6-4342-f789-1c3ce6d18cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaquín es fanático del Blackjack, por lo que en esta subsección implementarán métodos de RL y así generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Escriba su respuesta acá`"
      ],
      "metadata": {
        "id": "G5i1Wt1p770x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulación 5000 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?\n",
        "* ¿Cómo podría interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "RHCfKN7NGi1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "T0sp8XWsGg4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente?\n",
        "* ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "S7jdmnTwGePD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una función que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "Lssdp7AvGaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Descripción de MDP (0.2 puntos)**\n"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comencemos preparando el ambiente:"
      ],
      "metadata": {
        "id": "XvAVq1wQIjLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
      ],
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
        "* En la preparación del ambiente se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?"
      ],
      "metadata": {
        "id": "LNERH-m8JYQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Escriba su respuesta acá`"
      ],
      "metadata": {
        "id": "DbpGahPcHAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?"
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "pNMT_GORIreW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "Mg0epSnLKfy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "CWVY1a39KeRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.5 Optimización de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la función `export_gif` entregada para estudiar el comportamiento de su agente en la resolución del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, además, adjuntan el gif en el markdown tendrán un bonus de 0.1."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  función que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escriba su respuesta acá"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}